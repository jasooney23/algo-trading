{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "\n",
    "- simulate buying stocks (buy/sell decisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleDataset(price_changes, num_samples, interval_len, extension):\n",
    "    # creates samples of data from a dataset\n",
    "    # returns the intervals, and the target price changes\n",
    "\n",
    "    price_intervals = np.ndarray((num_samples, interval_len))\n",
    "    target_changes = np.ndarray((num_samples, extension))\n",
    "    for x in range(num_samples):\n",
    "        # print(x)\n",
    "        # start_index = np.random.randint(len(price_changes) - interval_len - extension)\n",
    "        start_index = round(x / (len(price_changes) - interval_len - extension))\n",
    "\n",
    "        price_intervals[x] = price_changes[start_index:start_index + interval_len]\n",
    "        # print(price_intervals[x])\n",
    "        target_changes[x] = price_changes[start_index + interval_len:start_index + interval_len + extension]\n",
    "        # print(target_changes[x])\n",
    "        # print()\n",
    "    \n",
    "    return price_intervals, target_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate hourly price changes for the ticker.\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv(\"a.csv\")\n",
    "\n",
    "TICKER = list(df.loc[:, \"Symbol\"])[:20]\n",
    "# TICKER = [\"MSFT\", \"AAPL\", \"NVDA\", \"MMM\", \"ABBV\", \"ADBE\", \"GOOGL\", \"T\", \"CMCSA\", \"DIS\", \"EA\", \"FOX\", \"META\", \"NFLX\", \"WBD\", \"ABNB\", \"TSLA\", \"AMZN\", \"DBX\"]\n",
    "# TICKER = [\"MSFT\"]\n",
    "\n",
    "# print(TICKER[96])\n",
    "\n",
    "DATASET_SIZE = 3500 # Number of samples PER TICKER\n",
    "INTERVAL = 7\n",
    "EXTENSION = 1\n",
    "\n",
    "# fetch hists\n",
    "try:\n",
    "    with open(\"hists.dat\", \"rb\") as f:\n",
    "        hists = pickle.load(f) \n",
    "except:\n",
    "    hists = []\n",
    "    for x in range(len(TICKER)):\n",
    "        print(\"LOADING TICKER \" + str(x) + \"/\" + str(len(TICKER)), end=\"\\r\")\n",
    "        hist = yf.Ticker(TICKER[x]).history(interval=\"1h\", period=\"2y\")\n",
    "        if not hist.empty and np.sum(np.isnan(hist.loc[:, \"Open\"].to_numpy())) == 0:\n",
    "            hists.append(hist)\n",
    "\n",
    "price_intervals = np.ndarray((len(hists), DATASET_SIZE, INTERVAL, 1))\n",
    "target_changes = np.ndarray((len(hists), DATASET_SIZE, EXTENSION))\n",
    "for x in range(len(hists)):\n",
    "    open_prices = hists[x].loc[:, \"Open\"].to_numpy()[:-1]\n",
    "    next_prices = hists[x].loc[:, \"Open\"].to_numpy()[1:]\n",
    "\n",
    "    ''' top: $ change, centered at 0\n",
    "        bottom: net change'''\n",
    "    \n",
    "    price_changes = (next_prices - open_prices) / open_prices * 100\n",
    "    # price_changes = next_prices - open_prices\n",
    "    # print(price_changes.shape)\n",
    "    \n",
    "    '''==='''\n",
    "\n",
    "    # print(open_prices.shape)\n",
    "    # print(next_prices.shape)\n",
    "    # print(open_prices[:5])\n",
    "    # print(next_prices[:5])\n",
    "    # print(price_changes[:5])\n",
    "    \n",
    "    intervals, target_changes[x] = sampleDataset(price_changes, DATASET_SIZE, INTERVAL, EXTENSION)\n",
    "    # if x == 0:\n",
    "    #     print(intervals[0])\n",
    "    # print(intervals.shape)\n",
    "    price_intervals[x] = intervals.reshape(intervals.shape[0], intervals.shape[1], 1)\n",
    "    # print(price_intervals[x, 0, 0, :5])\n",
    "\n",
    "    if(np.sum(np.isnan(price_intervals[x]))):\n",
    "        print(\"NAN: \" + str(x))\n",
    "        print(np.where(np.isnan(price_intervals[x])))\n",
    "        # print(intervals[0])\n",
    "        print(open_prices)\n",
    "        print(price_intervals[x][0][0])\n",
    "        display(hists[x])\n",
    "\n",
    "price_intervals = price_intervals.reshape((len(hists) * DATASET_SIZE, INTERVAL, 1))\n",
    "target_changes = target_changes.reshape((len(hists) * DATASET_SIZE, EXTENSION))\n",
    "\n",
    "with open(\"hists.dat\", \"wb\") as f:\n",
    "    pickle.dump(hists, f)\n",
    "\n",
    "def normalize(data):\n",
    "    return (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "# price_intervals = normalize(price_intervals)\n",
    "# target_changes = normalize(target_changes)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "# print()\n",
    "# print(price_intervals.shape)\n",
    "# print(target_changes.shape)\n",
    "# print(price_intervals[0, :, 0])\n",
    "# print(target_changes[0])\n",
    "# plt.hist(price_intervals[:, :, 0])\n",
    "# plt.show()\n",
    "\n",
    "# print(\"===\")\n",
    "# print(hists[0][:9][\"Open\"])\n",
    "# print(price_intervals[0, 0, 0])\n",
    "# print(target_changes[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "LEARNING_RATE = 0.001\n",
    "REG_FACTOR = 0 \n",
    "VAL_RATIO = 0\n",
    "\n",
    "# Define the LSTM model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Input((INTERVAL, 1)))\n",
    "# model.add(keras.layers.LSTM(units=64, kernel_regularizer=keras.regularizers.l2(REG_FACTOR)))\n",
    "# model.add(keras.layers.Dense(units=64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(REG_FACTOR)))\n",
    "# model.add(keras.layers.Dense(units=EXTENSION, activation=\"linear\", kernel_regularizer=keras.regularizers.l2(REG_FACTOR)))\n",
    "# model.add(keras.layers.LSTM(units=32, input_shape=(INTERVAL, 1), return_sequences=True))\n",
    "# model.add(keras.layers.Dropout(0.1))\n",
    "# model.add(keras.layers.LSTM(units=32, input_shape=(INTERVAL, 1)))\n",
    "# model.add(keras.layers.Dropout(0.1))\n",
    "# model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=64, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=EXTENSION, activation=\"linear\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.MSE, optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "\n",
    "model.build((None, INTERVAL, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 384\n",
    "\n",
    "# print(model.pjuredict(np.expand_dims(price_intervals[0], axis=0)))\n",
    "# Train the model\n",
    "model.fit(price_intervals, target_changes, epochs=num_epochs, batch_size=batch_size, validation_split=VAL_RATIO)\n",
    "\n",
    "# print(model.predict(np.expand_dims(price_intervals[0], axis=0)))\n",
    "\n",
    "# Evaluate the model\n",
    "# print(price_intervals.shape)\n",
    "# print(target_changes.shape)\n",
    "metrics = model.evaluate(price_intervals, target_changes)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(np.expand_dims(price_intervals[0], axis=0))\n",
    "print(\"PREDICTION: \" + str(predictions[0,0]))   \n",
    "print(\"ACTUAL: \" + str(target_changes[0,0]))\n",
    "print(\"ERROR (%): \" + str((predictions[0,0] - target_changes[0,0]) / target_changes[0,0] * 100))\n",
    "\n",
    "predictions = model.predict(price_intervals[:10,])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "\n",
    "def get_samples(hists, interval, type=\"change\", offset=0, steps=0):\n",
    "    num_hists = len(hists)\n",
    "    samples = np.ndarray((num_hists, interval + steps))\n",
    "    timestamps = np.ndarray((num_hists, 2), dtype=\"datetime64[s]\")\n",
    "    for x in range(num_hists):\n",
    "        hist = hists[x]\n",
    "\n",
    "        hist_times = np.asarray(hist.index.astype(np.int64) / (10 ** 9), dtype=\"datetime64[s]\")\n",
    "        timestamps[x] = np.array((hist_times[-interval - offset], hist_times[-1 - offset + steps]))\n",
    "\n",
    "        open_prices = hists[x].loc[:, \"Open\"].to_numpy()[:-1]\n",
    "        next_prices = hists[x].loc[:, \"Open\"].to_numpy()[1:]\n",
    "\n",
    "        price_changes = (next_prices - open_prices) / open_prices * 100\n",
    "\n",
    "        if type == \"change\":\n",
    "            samples[x] = price_changes[-interval - offset:price_changes.shape[0] - offset + steps]\n",
    "        elif type == \"open\":\n",
    "            samples[x] = open_prices[-interval - offset:price_changes.shape[0] - offset + steps]\n",
    "\n",
    "    return samples, timestamps\n",
    "\n",
    "def format_datetime(timestamp):\n",
    "    return timestamp.astype(datetime.datetime).strftime(\"%m/%d/%Y, %H:%M\")\n",
    "\n",
    "def plot(ticker, sample, timestamps, predictions=np.array((NaN,)), actual=np.array((NaN,)), actual_end=None, type=\"change\", offset=0, change_error=False):\n",
    "    print(\"=== \" + ticker + \": \" + type + \" ===\")\n",
    "    print(\"Start: \" + format_datetime(timestamps[0]))\n",
    "    print(\"  End: \" + format_datetime(timestamps[1]))\n",
    "    \n",
    "    sample = sample[offset:]\n",
    "    actual = actual[offset:]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 3))\n",
    "    ax_sample = fig.add_subplot(141)\n",
    "    ax_sample.plot(sample)\n",
    "    ax_sample.set_title(\"Sample\")\n",
    "\n",
    "    if predictions[0] != NaN:\n",
    "        # print(sample[-1])\n",
    "        # print(sample)\n",
    "        # print(predictions)\n",
    "        # print(np.cumsum(predictions))\n",
    "\n",
    "        \n",
    "        if type != \"change\":\n",
    "            predictions = sample[-1] * np.cumprod(predictions / 100 + 1)\n",
    "            # np.cumsum(predictions) + sample[-1]\n",
    "            # predictions = predictions + sample[-1]\n",
    "            \n",
    "\n",
    "\n",
    "        # print(predictions)\n",
    "\n",
    "\n",
    "        forecast = np.concatenate((sample, predictions))\n",
    "        ax_prediction = fig.add_subplot(142)\n",
    "        ax_prediction.plot(forecast)\n",
    "        ax_prediction.set_title(\"Prediction\")\n",
    "    else:\n",
    "        print(\"plot(): predictions either NaN or not given\")\n",
    "        \n",
    "    if actual[0] != NaN:\n",
    "        print(\"Actual prices end: \" + format_datetime(actual_end))\n",
    "        ax_actual = fig.add_subplot(143)\n",
    "        ax_actual.plot(actual)\n",
    "        ax_actual.set_title(\"Actual\")\n",
    "    else:\n",
    "        print(\"plot(): actual values either NaN or not given\")\n",
    "\n",
    "    if change_error:\n",
    "        ax_error = fig.add_subplot(144)\n",
    "        forecast = np.concatenate((sample, predictions))\n",
    "        ax_error.plot(forecast - actual)\n",
    "        ax_error.set_title(\"Error in prediction\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def predict(model, samples, steps):\n",
    "    '''FOR CHAINED PREDICTIONS'''\n",
    "    predictions = np.ndarray((samples.shape[0], steps))\n",
    "\n",
    "    # print(predictions.shape)\n",
    "    # print(samples.shape)\n",
    "    # print(np.expand_dims(samples, axis=1).shape)\n",
    "    for x in range(steps):\n",
    "        # print(model.predict(np.expand_dims(samples, axis=2), verbose=0).shape)\n",
    "        predictions[:, x] = model.predict(np.expand_dims(samples, axis=2), verbose=0)[:, 0]\n",
    "\n",
    "        samples[:, :INTERVAL - 1] = samples[:, 1:]\n",
    "        samples[:, INTERVAL - 1] = predictions[:, x]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 7\n",
    "BACK_OFFSET = 2\n",
    "TYPE = \"open\"\n",
    "\n",
    "input_sample, _ = get_samples(hists, INTERVAL, type=\"change\", offset=STEPS)\n",
    "samples, timestamps = get_samples(hists, INTERVAL, type=TYPE, offset=STEPS)\n",
    "actuals, actuals_end = get_samples(hists, INTERVAL, type=TYPE, offset=STEPS, steps=STEPS)\n",
    "\n",
    "# print(samples.shape)\n",
    "# print(actuals.shape)\n",
    "\n",
    "predictions = predict(model, np.copy(input_sample), STEPS)\n",
    "\n",
    "# print(samples.shape)\n",
    "# print(timestamps.shape)\n",
    "# print(actuals.shape)\n",
    "# print(actuals_end.shape)\n",
    "# print(predictions.shape)\n",
    "# print(predictions)\n",
    "# print(predictions[0:2])\n",
    "\n",
    "act_change, _ = get_samples(hists, INTERVAL, type=\"change\", offset=STEPS, steps=STEPS)\n",
    "\n",
    "\n",
    "for x in range(len(hists)):\n",
    "    plot(TICKER[x], samples[x], timestamps[x], predictions=predictions[x], actual=actuals[x], actual_end=actuals_end[x][1], type=TYPE, offset=INTERVAL - BACK_OFFSET, change_error=True)\n",
    "    # pred = predictions[x, :5]\n",
    "    # acts = actuals[x, -STEPS:-STEPS + 5]\n",
    "    # act_change = act_change[x, -STEPS:-STEPS + 5]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDEX = 0\n",
    "\n",
    "# # index = np.random.randint()\n",
    "# sample = (hists[INDEX].loc[:, \"Close\"] - hists[INDEX].loc[:, \"Open\"])[:INTERVAL]\n",
    "# sample = np.expand_dims(np.expand_dims(sample, axis=0), axis=0)\n",
    "\n",
    "# original = (hists[INDEX].loc[:, \"Close\"] - hists[INDEX].loc[:, \"Open\"])[:INTERVAL].to_numpy()\n",
    "# actual = (hists[INDEX].loc[:, \"Close\"] - hists[INDEX].loc[:, \"Open\"])[:INTERVAL + EXTENSION].to_numpy()\n",
    "# # print(sample.shape)\n",
    "# # print(sample)\n",
    "# predictions = predict(model, sample)\n",
    "# extended = np.concatenate((original, predictions))\n",
    "\n",
    "# print(\"Original plot\")\n",
    "# plt.plot(original, color=\"blue\")\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Extrapolated plot\")\n",
    "# plt.plot(predictions, color=\"blue\")\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Actual plot\")\n",
    "# plt.plot(actual[INTERVAL:], color=\"blue\")\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Difference (pred - real) plot\")\n",
    "# plt.plot(predictions - actual[INTERVAL:], color=\"blue\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
